{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIiOqHrvagAsHh90OWc8z3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KARANBUNKAR/Ml-assignment-/blob/main/dataset%20exploration%20and%20splitting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIT1vgeE_X3q",
        "outputId": "9ce4d462-fa52-46c8-ede6-6ccc24ccc356"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First five rows of the dataset:\n",
            "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
            "0                5.1               3.5                1.4               0.2\n",
            "1                4.9               3.0                1.4               0.2\n",
            "2                4.7               3.2                1.3               0.2\n",
            "3                4.6               3.1                1.5               0.2\n",
            "4                5.0               3.6                1.4               0.2\n",
            "\n",
            "Shape of the dataset:\n",
            "(150, 4)\n",
            "\n",
            "Summary statistics:\n",
            "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
            "count         150.000000        150.000000         150.000000   \n",
            "mean            5.843333          3.057333           3.758000   \n",
            "std             0.828066          0.435866           1.765298   \n",
            "min             4.300000          2.000000           1.000000   \n",
            "25%             5.100000          2.800000           1.600000   \n",
            "50%             5.800000          3.000000           4.350000   \n",
            "75%             6.400000          3.300000           5.100000   \n",
            "max             7.900000          4.400000           6.900000   \n",
            "\n",
            "       petal width (cm)  \n",
            "count        150.000000  \n",
            "mean           1.199333  \n",
            "std            0.762238  \n",
            "min            0.100000  \n",
            "25%            0.300000  \n",
            "50%            1.300000  \n",
            "75%            1.800000  \n",
            "max            2.500000  \n",
            "\n",
            "Number of samples in the training set: 120\n",
            "Number of samples in the testing set: 30\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "data = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "target = pd.Series(iris.target, name='species')\n",
        "\n",
        "# Display the first five rows of the dataset\n",
        "print(\"First five rows of the dataset:\")\n",
        "print(data.head())\n",
        "\n",
        "# Display the shape of the dataset\n",
        "print(\"\\nShape of the dataset:\")\n",
        "print(data.shape)\n",
        "\n",
        "# Display summary statistics\n",
        "print(\"\\nSummary statistics:\")\n",
        "print(data.describe())\n",
        "\n",
        "# Split the dataset into training and testing sets (80-20 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the number of samples in the training and testing sets\n",
        "print(\"\\nNumber of samples in the training set:\", len(X_train))\n",
        "print(\"Number of samples in the testing set:\", len(X_test))\n"
      ]
    }
  ]
}